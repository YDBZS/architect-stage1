## 1、分布式消息队列(MQ)设计与落地

### 1、分布式消息队列(MQ)认知提升

### 2、RabbitMQ实战

### 3、RabbitMQ可靠性投递基础组件封装

### 4、Kafka应用实战

### 5、Kafka高吞吐量日志收集实战

### 6、架构思考：分布式日志、跟踪、告警、分析平台

## 2、第一节内容

### 1、业界主流的分布式消息队列(MQ)与技术选型

### 2、预习与复习 - ActiveMQ特性原理与集群架构

### 3、RabbitMQ特性原理与集群架构解析

### 4、[预习和复习]RocketMQ特性原理与集群架构

### 5、Kafka特性原理与集群架构解析

## 3、业绩主流的分布式消息队列(MQ)与技术选型

### 1、分布式消息队列(MQ)应用场景

#### 1、服务解耦

+ 比如说系统之间如何去做解耦，服务之间如何去做一个拆分和隔离
+ 服务的拆分和隔离是业务层面的一个划分。
+ 那既然拆分和隔离之后呢，怎么去保持通信，这要看服务依赖性到底是强依赖还是弱依赖。
+ 这个就是微服务的一个技术手段了。
+ 如果是强依赖的话，那可能采用的就是级联的方式。
+ 比如说同步的dubbo调用，同步的http做SpringCloud。
+ 如果是弱依赖呢，可以去采用消息中间件，去做消息的解耦。
+ 当然如果是弱依赖不代表着是说我可以失败，那弱依赖不能失败。
+ 比如说我们上游的服务去做一次消息的发送，发送MQ，然后下游的服务一定要收到这条消息。
+ 然后并做一个相应的消费处理
+ 那这个时候，可能就需要上游服务去做一个可靠性的投递了。
+ 那这个是后面的事情。

#### 2、削峰填谷

+ 比如说在生产环境中如果你存在一些即时性很高，或者说是流量很大的一些应用场景。
+ 比如说秒杀或者是一些大促的一些业务场景下。
+ 那你如何去对你的一些应用服务去做一个抗压。
+ 那就需要去做一个MQ的削峰和填谷。
+ 削峰和填谷的意思就是说把流量的高峰和低谷的一个速率去做一个均衡。
+ 那我们MQ它本质上早期做的就是这个事情。
+ 他做的事情就是说当我的下游服务处理不过来之后，我可以把消息缓存到一个地方。
+ 然后慢速去消费。那这个就是一个削峰。
+ 当然大促他不可能持续的时间很长，比如说是双十一的大促。
+ 他可能持续了半小时一小时，后面相对而言就会比较平稳了。
+ 那我就可以把开始的大促的消息，把它挤压到，囤积到MQ的消息中去，然后慢慢的去做一个消费。
+ 那这也是可以的。

#### 3、异步化缓冲

+ 有些业务逻辑可以允许一些异步的操作。
+ 只需要做到最终一致性即可。不需要去做一个实时的强一致性。
+ 只需要去做一个最终的一致性。
+ 类似于这种柔性的事务。
+ 那就本上就是消息中间件实际的应用场景。

### 2、分布式消息队列(MQ)应用思考点

+ 就说分布式消息队列在使用的时候，既然你已经选择了MQ去做这件事情，那么你需要思考那些问题呢？
+ 比如说你能够保证消息的可靠性投递，或者是怎么样。
+ 要考虑某些你需要关注的点。

#### 1、生产端的可靠性投递

+ 如果是金融领域相关的，那消息是一定不能丢失的。
+ 一定要做到生产端的百分之百可靠性投递。
+ 就这条消息发出去了，跟数据库一定要保障一个原子性才行。
+ 那这个通常怎么去解决呢？后面说

#### 2、消费端的幂等

+ 生产端想做到可靠性投递，可能会有重复的消息，如果重复的消息我消费端消费了两次。
+ 或者多次的话，那这个数字肯定就不一致了。
+ 所以说消费端一定要做一个幂等性的验证，不能让这个消息消费丢失。
+ 比如说消息只能消费一次。
+ 然后呢MQ还需要考虑到哪些点呢？
+ 剩下的可能是MQ本身的一些特性了。

#### 3、高可用

+ 如果说应用服务其中有一个MQ的Broker节点挂掉了。宕机了，磁盘不可用了。
+ 那怎么去保障它的一个高可用？

#### 4、低延迟

+ 在巨量的峰值，流量非常非常大的冲压冲过来的时候，如何能保障一个低延迟以及是消息的可靠性？
+ 就是说消息落到MQ我是否能够保障他肯定不会丢失？
+ 如果说磁盘发生损坏，那是不是有一些相应的解决手段。
+ 比如说高可用就是HA(high available).
+ 可靠性说白了现在业界主流的技术框架是怎么解决的呢？无非就是reply key这种方式。
+ 就是副本的方式
+ 比如说Kafka，甚至是说ES，他都会有一些分片和副本的概念，以及是消息堆积能力。

#### 5、消息堆积

+ 那应对于你的业务场景下，你到底有多少个数据，多少个数据量，然后呢大体预估一下，我的消息在高峰期能够堆积到什么程度。
+ 那这也是非常非常有必要去考量的。
+ 那后面再去做技术选型的时候，一定要衡量这个MQ能不能抗住目前的业务场景下的冲击。
+ 如果扛不住，那就是存在问题的。
+ 存在问题就是不能选择的。
+ 这是第一点
+ 第二点就是说如果他做不到高可用，那会不会有问题，他做不到可靠性，做不到低延迟。
+ 会不会给业务带来瓶颈？会不会给业务带来一些麻烦呢？
+ 这些都是作为一个架构需要去认真思考的一些点。

#### 6、扩展性

+ 比如说你的消息队列能否支持天然的无感知的横向扩容呢？这些也是相应来讲需要考虑的一些问题。

## 4、业界主流的分布式消息队列(MQ)

### 1、ActiveMQ

+ 他是一个非常经典的比较古老的一个MQ，他的功能其实是非常强大的。
+ 也是apache的顶级的开源消息中间件。
+ 在以前在一些中小型企业做一些企业级的管理系统，应用是非常的广泛的。

### 2、RabbitMQ

+ 他其实是和ActiveMQ差不多。
+ RabbitMQ也是业界非常流行的主流的消息中间件。
+ 这个也是当前模块重点要去讲的。

### 3、RocketMQ

+ RocketMQ之前呢也是Alibaba开源的一个消息中间件。
+ 现在是已经交给了apache。
+ 目前也是到了4.5.1这个版本。支持了很多功能。
+ 丰富的消息拉取和消费机制，包括消息同步消费机制。
+ 这个也是目前一个非常主流的消息中间件。
+ 现在也是支持了分布式的事务。

### 4、Kafka

+ 他主要是关注与高吞吐量和一个海量数据的存储。
+ 这四种消息中间件是业界非常非常主流的。

## 5、如何去做技术选型？

### 1、关注各个MQ的性能，优缺点、相应的业务场景

+ 像ActiveMQ最开始接触，它是适合于传功同行业，中小型公司。
+ 并且它的并发或者说是消息的承载能力不是那么特别特别的优秀。
+ 比如说你想应对天猫，双十一大促的场景。
+ 那ActiveMQ很明显是不满足需求的。
+ 如果公司里面的业务如果是高并发，海量数据，大流量的需求的话。
+ 如果想要去做服务的解耦。
+ 如果要去用ActiveMQ的话很明显不是特别合适的。
+ 但是如果你说这是中小型的业务系统，或者说互联网公司内部边缘的系统。
+ 想去用ActiveMQ这完全是没有问题的。
+ 他应对于不同的场景。
+ 如果是RabbitMQ的话，很明显是可以满足需求的。
+ 但是呢RabbitMQ他也有瓶颈，RabbitMQ后面要去学习它的一个集群模型。
+ 他有这种镜像队列，主要是满足这个数据不丢失。
+ 就是可靠性，高可用，但是呢RabbitMQ横向扩展能力不是特别好。

### 2、集群架构模式，分布式、可扩展、高可用、可维护性

+ ActiveMQ，RabbitMQ，RocketMQ以及是Kafka，其实都有自己的一个集群架构模型。
+ 以及分布式的实际的搭建。
+ 但是可扩展性还有就是可用性以及可维护性，后面这三点，就要针对某些不同的MQ。他自己有自己的特点。
+ 举个例子，像RabbitMQ，它的可能可扩展性不是那么特别好，需要自己加一层自己的日志组件。
+ 但是它的可用性和可维护性这个都是业界首屈一指的。
+ 像Kafka或者说刚才所说的RocketMQ，它的扩展性是非常强的。
+ 高可用性也是具备的，但是呢可维护性也是可能稍微有一点点麻烦。

### 3、综合成本问题，集群规模，人员成本

+ 除了硬性的指标，还要需要考虑一些实际的情况，比如说结合综合的成本。
+ 还有就是集群的规模。
+ 以及是人员的成本。
+ 人员成本指的是什么意思呢？
+ 比如说一个团队里，他可能对MQ的认知可能说不是特别特别的清楚。
+ 或者说相对来讲，有些MQ应用的不是特别的多。
+ 那就需要看公司的技术栈，大家对哪一种MQ比较熟悉，或者说这一种架构。
+ 你能hold住哪一种架构。
+ 并且能满足你的业务需求，那么你就可以去做一个最终的技术选型。
+ 当然也要考虑各方面，比如说可扩展性，扩容。伸缩性，以及可用性。
+ 数据丢了，磁盘坏了，怎么去做恢复。
+ 这些都是需要综合去考虑的。

### 4、未来的规划，方向和思考

+ 所以说针对于技术选型，其实不仅仅是MQ本身上的优缺点。
+ 一定要结合着业务场景以及对于集群搭建的分布式扩展性，可用性，可维护性的一些特性。
+ 以及再结合到你实际的一些集群规模和人员成本。
+ 集群规模是什么意思呢？
+ 比如说我们的消息不是那么特别要求可靠性，对可靠性依赖不是特别高。
+ 那完全是可以用Kafka。
+ 因为Kafka可以在很廉价的服务器上有着非常非常高的性能以及是吞吐量表现。

## 5、RabbitMQ特性原理与集群架构解析

### 1、RabbitMQ四种集群架构

#### 1、主备模式

+ 主备模式可以理解为是热备份。
+ 就是说我有一个Master，还有一个Slave。
+ 正常情况下Master是对外提供读写的，而Slave仅仅是做一个备份。
+ 当出现异常的时候，比如说Master故障宕机的时候，会做一个切换。
+ 然后Slave节点会升级成一个Master节点。
+ 这种方式也是一种非常经典的模型。

#### 2、远程模式

+ 远程模式是RabbitMQ早期版本提供的一种多活的存储。
+ 主要是做数据的异地的容灾，异地的转移的。
+ 那他也是可以提升性能的。
+ 比如说当单节点，就是说单个集群处理不过来的时候，可以把消息转发到下游的某一个集群模型中。
+ 这种方式它的架构其实非常简单，但是它的配置说白了就非常的复杂。
+ 所以说后面也考虑一般都会用多活模式来替代这种远程模式。
+ 远程模式进进去了解一下就可以了。

#### 3、镜像模式

+ 这种镜像模式是业界使用非常广泛的RabbitMQ集群架构的模型。
+ 这种模型能够保障消息是非常可靠的。

#### 4、多活模型

+ 多活模型和远程模型也差不太多，都是去做一个异地的容灾或者双活，或者数据的一个转储功能。
+ 路由转发的功能。

### 2、四种集群架构模式详解

#### 1、主备模式(warren(兔子窝))

+ 一个主/备方案(主节点如果挂了，从节点提供服务，和ActiveMQ利用Zookeeper做主/备一样)
+ 通常就是一个主节点加一个备份节点，是一种主备的方案，采用的是主备的方案。
+ 当然是热备份。
+ 如果是主节点，由于某些故障坏掉的话，从节点可以继续的去提供服务。
+ 去做一个切换，RabbitMQ他也是一种主备的机制。
+ 当RabbitMQ的master挂掉的话，会运用zookeeper去做一个切换。
+ 因为切换的话也是秒级的。不会说太影响整个MQ的使用情况。
+ 也是做了一个热备份，只不过区别点就在于RabbitMQ的主备模式采用的就是HA proxy去做的。
+ 而之前的ActiveMQ它采用的是zookeeper去做的主备。

![image-20220628150949380](assets/image-20220628150949380.png)

+ 看一下这个主备模型
+ 上面可能是Consumer或者是Provider，就是生产消费者。
+ 总之呢，在这里的一个Consumer指的不仅仅是消费者，他可以理解为是一个需求方。
+ 通过HaProxy去路由到默认，是路由到主节点，master。
+ 然后默认就是master去提供服务。
+ 当master出现故障的时候，下一次路由在HaProxy里面配置了一些规则以后。
+ 他会帮忙路由到备份节点。备份节点会升级为主节点。
+ 当主节点再次修复好了之后呢，那他也是加入到集群了，称为原来备份节点的备份节点。
+ 说白了就是主节点会进行一个漂移。
+ 有点类似于keepalived里面的IP漂移的概念。
+ 那下面就是一个共享存储了。

#### 2、主备模式-HaProxy配置

```shell
listen rabbitmq_cluster
bind 0.0.0.0:5672    # 配置tcp模式
mode tcp 			 # 简单的轮询
balance roundrobin	 # 主节点
server bhz76 192.168.11.76:5672 check inter 5000 rise 2 fall 2
server bhz77 192.168.11.77:5672 backup check inter 5000 rise 2 fall 2 # 备用节点
```

+ 对于HaProxy的listener就是主备模型的一个集群名字，这里叫做rabbitmq_cluster
+ 绑定的端口就是5672
+ 下面就是轮询的模型，轮询的mode是tcp还是http呢？还是其他的一些协议？
+ 其实HaProxy在课程中也会去扩展一些其他的技术点。
+ HaProxy其实和Nginx也差不多，Nginx也提供了很多包括TCP还是http这种协议。
+ 这种轮询的模式。对于轮询模型，主流的轮训模型就是rounding，就是轮训。
+ 还有就是最小连接数的load balance策略。
+ 包括hash，通过hash算法去做ip_hash等等。
+ 这种轮询策略。
+ 看一下HaProxy，主节点就是这个76，备份节点就是下面的77.
+ 主节点去做一个check，每五秒钟去做一个check，如果两次失败的时候。会切换到下面比较长的配置里面。
+ 这个配置就是备份节点。
+ 它比上面唯一的区别就是多了一个backup配置。backup关键字。
+ 这个其实就是兔子窝主备的一个配置。

#### 3、远程模式

+ 远程模式它的概念就是远距离的通信和复制。
+ 可以实现双活的一种模式，简称Shovel模式。
+ 这种远程模式在现在来看他用的其实并不多。
+ 因为它的可靠性可能还有待提高。并且它的配置也非常非常的麻烦。
+ 所谓Shovel就是可以把消息进行不同数据中心的复制和转移的工作。
+ 当上游的MQ比如说压力过大的时候，有些消息收不过来了。
+ 可以把它堆积到另外一个地方。然后让两个集群进行一个互联。
+ 这么的一个操作。

#### 4、Shovel架构模型

![image-20220628153358123](assets/image-20220628153358123.png)

+ 用户通过website发消息到第一个RabbitMQ集群去做消费处理。
+ 这里面有一个Shovel叫做replicated，就是说消息可以被转发到下游的另外的一个MQ中心集群。
+ 也可以去做一个消费处理。
+ 它不仅仅是能够做一个容灾，而且还可以提高订单的消费速度。
+ 这里面是存在一个order的。

![image-20220628153702346](assets/image-20220628153702346.png)

+ 这个是第二个MQ的集群，它是可以帮助去做一个路由的转换。
+ 也就是说当地一个集群消费不过来的时候，可以去转到第二个。
+ 当地一个集群出现问题的时候，也可以转到第二个。这个就是一种多活的方式。

#### 5、Sholve集群配置步骤

+ 为什么说现在用得不多呢？
+ 原因就是配置非常非常的复杂。
+ 配置在这里读一读就可以了，因为在实际工作中很少人去使用这种远程模式。

##### 1、Step1：启动RabbitMQ插件

```shell
rabbitmq-plugins enable amqp_client
rabbitmq-plugins enable rabbitmq_shovel
```

+ 首先要启动RabbitMQ的插件，这个RabbitMQ插件首先要启动amqp_client
+ 为什么呢？因为远程模式他们MQ之间集群的通信，是用到了mq的mqp协议，然后去做通讯的。
+ 然后呢还要enabled shovel插件。这仅仅是第一步。

##### 2、Step2：创建rabbitmq.config文件

```shell
touch /etc/rabbitmq/rabbitmq.config
```

##### 3、Step3：添加配置rabbitmq.config

![image-20220628154831871](assets/image-20220628154831871.png)

##### 4、Step4：源与目的地服务器使用相同的配置文件(rabbitmq.config)

##### 5、看一下rabbitmq的配置多复杂

+ 大体上就是说你当前两个集群想要建立关联有一个source就是源。
+ 还有一个destinations。
+ 对于每一个broker它的地址要配置一下。
+ 对于declarations，要说明什么队列需要去帮我去做一个shovel。
+ 什么交换机，怎么去绑定规则，就是每次建一种Exchange交换机。
+ 每次建一种队列的时候，可能都需要在里面去加一个配置。
+ 就是把这个路由去通过配置写上。
+ 如果以后要加配置。
+ 如果要想加队列想帮我路由到下游的destination.
+ 那就需要在配置里面还要去加。
+ 就是说这个是非常非常不方便的。运维起来非常麻烦的这种方式。
+ 不建议太深入的对Shovels模式学习。
+ 当然目前业界使用RabbitMQ集群最主流的还是镜像模式。

#### 6、镜像模式

+ 镜像模式非常经典的就是Mirror镜像模式，保证100%数据不丢失。
+ 那他是怎么去保证的呢？
+ 镜像的概念其实就是一个复制。
+ 在实际的工作中用的最多，并且实现集群非常的简单，一般互联网大厂都会构建这种镜像集群模式。
+ 镜像模式其实说白了就是数据的备份。
+ 镜像模式业界有哪些或者说有哪些技术是使用复制的概念？
+ 其实最主流的或者说是最显而易见的。
+ 如果对mongoDB熟悉的话，他有一种模型就叫做复制集replication这种方式。
+ 这种其实跟他是比较相像的。
+ 或者说ElasticSearch中的一些replicate副本的概念。
+ 当然它的缺点也会有。这个后面再说。

#### 7、Mirro镜像队列

##### 1、可靠性

+ 数据不会丢，因为它的数据发过来，他要同步到对应的镜像集群内部所有所有的节点。
+ 都会去做一个数据的备份存储。
+ 所以说即使是说你集群中有一个节点挂掉了。
+ 有一个节点磁盘坏了。没关系，通过镜像队列的恢复手段都可以做一些恢复。

##### 2、数据同步

+ 因为知道RabbitMQ它的底层是erlang去写的，天然的交换机的方式。
+ 他有跟原生Socket一样低的延迟。
+ 所以说他的性能在做数据同步的时候是非常好的。

##### 3、3节点

+ 保证可靠性最好是奇数个节点。
+ 一般做集群都会去选择奇数个节点，第一点防止脑裂。
+ 脑裂就是做选举的时候更快把master去选出来。

#### 8、RabbitMQ集群架构图(如何去搭建RabbitMQ镜像队列)

![image-20220702170813314](assets/image-20220702170813314.png)

+ 这幅图就是一个完整的镜像队列的模型。
+ 先最下面去看，最下面是三个节点的MQ服务器，他们分别是三个mirrior queue。
+ 也就是说三个节点数据保存都是一致的。
+ 再往上看，就是上游的服务。
+ 在这里就直接是写死了，就是SpringBoot Application。
+ 他去访问镜像服务器，MQ服务器，他不是直连的，他是通过一层中间的代理层。
+ 中间的代理层蓝色的是什么呢？
+ 还是用Ha_proxy。
+ 但是在这里还是加了一个keepalived。
+ 因为是当Ha_proxy如果是单点的话，如果发生故障，这台服务器如果是挂掉了。
+ 有问题了，就整个就提供不了服务了。
+ 所以说是利用keepalived去做一个高可用。
+ 他会虚拟出来了一个VIP。
+ 那应用服务直接去通过VIP跟两台HA_proxy去打交道。
+ 当然请求过来之后也只是路由到其中的一台。
+ 然后由其中一台的Ha_proxy供负载均衡到三个最下面的，最底层的mirror_queue上面。
+ 这个其实就是一个镜像队列集群。
+ 后面也会详细的去说明镜像队列如何去搭建。
+ 最后的话想象一下，镜像队列存在一个天然的缺陷是什么？其实一眼就看出来了。
+ 缺陷就是说它不能支持横向的扩展。
+ 因为它的数据存储是有限的。当数据量尤其在高峰期的时候，一旦是流量非常大。
+ 可能消费者消费速率没有那么快。
+ 那消息都会堆积到镜像队列上。
+ 那横向扩容根本就是没有意义。
+ 横向再扩容它是增加了RabbitMQ集群的负担。
+ 因为四个节点四份数据要同步。那肯定性能上，吞吐量上一定是有所降低的。
+ 所以官方也建议说如果镜像队列集群集群三个就好了。
+ 三个其实能够保障一个可靠性。奇数个节点。
+ 也就是说最小奇数个节点。
+ 但现在如果是想说想要横向扩容的话，应该怎么办呢？
+ 在这里官方提供了一种叫做多活模式。
+ 就是下面要讲解的解决镜像队列一种无法横向扩容的缺点把。

#### 9、多活模式

+ 这种模式其实也是实现异地数据复制的主流模式，因为Shovel模式配置比较复杂。
+ 所以一般来说实现异地集群都是使用这种多活模式或者多活模型来实现的。
+ 多活模式其实相比于远程模式，就是Shovel，其实肯定是有优点的。
+ 因为Shovel远程模式它的配置非常复杂。
+ 多活模型要依赖RabbitMQ的federation插件，可以实现持续的可靠的AMQP数据通讯。
+ 并且也是可以实现多活。两个RabbitMQ集群中心。
+ 这样的话从宏观的角度来讲，让整个的应用服务更加的稳定一些。
+ 对于多活模式，RabbitMQ其实也是采用双中心或者是多中心的概念了。
+ 两套或者多套数据中心各有一套MQ集群。
+ 每个中心的集群除了提供自己的所需的服务之外，对于一些关键的数据，还可以数据的一些互通。
+ 一些共享。这就是faderation集群的最重要的特点。

#### 10、看一下多活模型的一个架构图

![image-20220702173226753](assets/image-20220702173226753.png)

+ 也就是说上面的这个Application是一个应用，然后是哦LBS负载均衡。
+ 下面是负载到三个节点。右边的话也是负载到三个节点。
+ 这个可能就是一个镜像队列集群。右边可能也是一个镜像队列集群。
+ 有一些数据要是能够保障不丢失的话，或者是能够保证两个集群之间的异地互通。
+ 中间就是可以使用Federation插件。
+ 去做消息的连接就可以了。

#### 11、多活模式-Federation插件

+ Federation其实是一个不需要构建Cluster的这种方式。
+ 其实本身自己的集群内部已经是镜像队列了。
+ 所以说你就说没有必要在搞一个Federation集群了。
+ 直接让他去做一个插件，让两个集群之间消息相互之间的传输。
+ 做一个高性能的传输就可以了。
+ Faderation插件可以在Broker或者Cluster之间进行消息传输。
+ 连接的双方可以使用不同的Users和Vitual hosts。
+ 就是说它不在意你的User权限以及vitual host。
+ 双方也可以使用不同版本的RabbitMQ和Erlang。
+ 这两个东西你可以认为是完全独立的。那他是怎么去做的呢？
+ 无非就是统一了一个协议。
+ 就是大家版本都不同，没关系，那协议相同就好了。
+ 所以说Faderation插件就是使用RabbitMQ经典的AMQP协议通讯即可。
+ 可以接受不连续的数据传输。这个就是Faderation最优秀的地方。
+ 就是版本要升级都没问题。可能就是有一些历史遗留原因。
+ 一个中心的RabbitMQ集群他可能搭建的比较早。
+ 但是想用新的，没关系。他们两个想互通，也是可以的。

#### 12、Faderation Exchanges

+ Faderation它本质上其实就是一个Exchanges。
+ 可以看成DownStream从Upstream主动拉取消息。
+ 也就是说下游从上游主动拉取消息，但并不是拉取所有的消息。
+ 其实这个东西就和之前所说的远程模式Shovel差不多。
+ 但是他解决了Shovel的配置问题。
+ Shovel只能是在配置文件里面去配置。没有办法动态的去做。你想要去加一个Exchange。
+ 去让这两个集群多一个Exchange去做同步的时候。
+ 你必须要重启服务，然后再配置文件里先配置好之后，再起来。
+ 这就是非常麻烦。
+ 但是Faderation它的优点是什么呢？它的优点就是你想去加哪几个Exchange去进行相互之间的通讯和转发。
+ 所以你直接可以通过控制台操作就好了。
+ 所以就支持可视化，而且是即时生效的。
+ 不需要写一些复杂的配置。也是支持热更新的。
+ 必须是DownStream已经明确了绑定关系的Exchange。
+ 也就是说DownStream一定要UpStream的Exchange的一个绑定。
+ 这样的话他才能够通过DownStream自己的一个物理的队列去拉去Upstream给我传过来的一个消息。
+ 这里面也就是说AMQP它实现的是中间两个集群的通信代理。
+ DownStream会将绑定关系组合在一起。
+ 绑定解除命令也可以去做。
+ 也就是说你说我配完了之后，我两个集群之间我不想去做通讯了。可以直接通过控制台。
+ 把Exchange直接连接的一个桥梁给他删除掉就可以了。
+ 所以说这是非常非常方便的。

#### 13、Faderation图解

![image-20220702175516558](assets/image-20220702175516558.png)

+ 左边是Upstream，就是上游，下面肯定就是DownStreasm了。
+ Upstream和DownStream存在什么区别呢？
+ 他们之间是存在一个UpStream link。
+ 他是一个上游的连接。
+ 下游一定要绑定上上游的一个Exchange。
+ 他们之间才能连上。
+ 上游也是可以消费的，上游消费完了之后也可以把消息转发给下游。
+ 然后下游也是可以去做一个具体的处理。
+ 这是一个Faderation，当然这里面他自己也是可以发消息处理。
+ 也就是说你可以认为是两个完全独立的镜像队列集群，只不过可以利用Faderation插件实现上下游的一个灵活的消息的转储解决方案。
+ 这里面就是想要去介绍的一个Faseration。
+ 这也是整个RabbitMQ它的核心架构的讲解。

## 6、Kafka特性原理与集群架构解析

## 7、Kafka介绍

+ Kafka是Linkedln开源的分布式消息系统，目前归属于Apache顶级项目。
+ Kafka主要特点是基于Pull的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输。
+ 也就是说做一个拉模式的消息处理。
+ 对于Kafka是存在很多版本的。
+ 0.8版本以后就开始支持复制，但是不支持事务，因为Kafka既然是去追求高性能，肯定是不能去加事务的。
+ 事务毕竟是会损耗性能的。
+ 但是对于消息的重复消费，丢失还有错误并没有严格的要求。
+ 因为它本身来讲就是左收集日志的。
+ 那几百万，几千万，上亿条，几十亿条数据中丢失的两三条其实是无所谓的。
+ 它适合在生产大量数据互联网服务中去做业务数据的一个收集。
+ 如果你想去做消息一条不丢，那Kafka能不能实现呢？
+ 这个答案是肯定的。是可以实现的。
+ 但是实现的话，性能就会降的比较多了。
+ 所以说呢正常来讲去选择Kafka都是可以容忍它极少量的数据的丢失。

## 8、Kafka有哪些特点？

​	其实在面试各消息中间件你是存在什么看法的时候，经常会出现一些MQ之间的一个对比。

### 1、分布式

+ Kafka支持消息的一个分区的概念。
+ Kafka里面非常核心的一个概念就是Partition。一个Topic下面可以有很多个Partition。
+ 然后呢Partition和对应的Consumer也一定是要一一对应上的。
+ 比如说你一共就四个Partition，那你十几个Consumer的话。
+ 那肯定是很多Consumer就是浪费了。没有任何意义的。
+ 这其实就是和很多MQ初衷都是类似，都是相像的。

### 2、扩平台

+ 他支持不同语言的客户端。
+ 比如说是Java，PHP或者是Python，都支持。
+ 所以说它使用起来也是非常非常友好的。对于一些异构的系统。

### 3、实时性

+ 数据支持实时处理，和一键处理。
+ 那即使你的Kafka堆积了上亿，几十亿的数据。
+ 只要你的存储是OK的。他不会影响Kafka的性能。这个其实在之前的工作中也有遇到过。
+ 因为之前是用Kafka做日志收集。之前做日志收集是用的ES。
+ 因为是ES的磁盘满了，导致ES已经去做限流了，然后所有的消息都堆积到Kafka了，堆积将近能有一个七八个小时。
+ 之前的工作量是非常大的。七八个小时这种堆积了几十TB的数据。
+ 就是数据的这个量差不多是几十亿。都存到Kafka了。
+ 但是它并不影响Kafka的消息的接收和发送能力。
+ 所以这也说明了Kafka消息堆积能力是非常非常强的。绝对是上亿级的消息堆积能力。

### 4、伸缩性

+ 伸缩性也是非常强的。支持水平的扩展。、

### 5、总结

+ 在面试的时候，一定要谈到这四点。
+ 有人说这四点需要我背下来嘛？
+ 其实是不需要背诵的。
+ 作为是一个架构设计者，当你学这们课程的时候，只需要从架构设计的角度去出发，去考虑。
+ 如果你的系统是异构系统的话，那毕竟是多语言，无论是Java，Python还是PHP包括其他的...
+ 你就要知道异构的首选，你要选择支持异构的中间件。
+ 第二点就是说他支不支持分布式。
+ 还有就是第三点它的一个实时性。还有一键处理，还有就是消息堆积能力是不是足够强。
+ 支不支持扩展。
+ 就是作为架构选型最开始的需要关注的点。

## 9、Kafka高性能能的原因是什么？(重点)

### 1、顺序写，Page Cache(空中接力，高效读写)

#### 1、什么是顺序写？

+ 其实真正的就是一个顺序写盘。
+ 顺序写盘的过程其实可以提高磁盘的利用率。
+ 比如说Consumer通过offset顺序消费数据，而不删除已经消费过的数据。
+ 从而避免磁盘的随机写，随机写的一个过程。
+ 通过自己说的这句话，脑海里是存在什么概念呢？
+ 回想一下业界主流的种种MQ。
+ 其实RocketMQ他也是借鉴了Kafka很多的特性，在自己业务的基础上去做了一个扩展。
+ 如果你要做一个MQ那怎么去设计这个MQ的存储呢？
+ 很显而易见的就是你要做到顺序写。
+ 什么意思，就是说MQ里的数据，我的生产者把数据发送到了MQ的Broker。
+ 然后我要存到磁盘的某一个点。
+ 我一样记录一个位置，这个位置也就是offset。
+ 然后这个offset肯定都会被Consumer去消费。
+ 他消费的时候肯定会记录一下他当前消费的位置是在哪里。
+ 就是他要记录下他消费的这个Offset。然后它基于这个offset之后。
+ 他继续去往下去找下一个Offset，然后去消费。
+ 只有这个过程才能够充分的去利用磁盘的利用率。
+ 因为这才是顺序写，一个一个的写。而不是说随机写。
+ 他不是随机写的。如果你消费完了这个消息，然后你把这个消息从这个文件中的某一点去给他删掉。
+ 那你想一下这整个的文件，整个的offset会不会有变化。
+ 他是不是会产生一个偏移。
+ 所以说一般MQ的设计都会去不允许删除消息。这是重点。
+ 如果是你用过一些云服务的话，就阿里云上的这个消息中间件MQ。
+ 这个阿里云上的消息中间件支持删除某一些消息。
+ 那他这个是怎么去做到的呢？
+ 肯定不是直接把文件中的某一个offset对应的消息删除的。
+ 而可能是做一层转储。然后按照标记去做的。
+ 相对来讲它的删除就可能不是物理删除，而是一些逻辑上的让你不可见。

#### 2、什么是Page Cache？

+ Kafka第一点高效的读写，他其实是利用了PageCache的这种空中接力的方式。
+ 还有等等就是说后台异步的一些Flush策略，IO调度的一些策略，
+ 内部实现其实是比较复杂的。
+ PageCache这个东西它能够去做什么呢？
+ 就是说可以在廉价的服务器上我都能支持单机，每秒100000一条以上这样的一个吞吐量。
+ Kafka说你不要害怕文件系统
+ Kafka它的这样一个文件系统就是简简单单的去做顺序的去读普通的文件。
+ 借力于Linux内核的Page Cache。不显示的去用内存，而胜似用内存。

### 2、高性能，高吞吐

+ 这个就是Kafka它的一个初衷了。
+ 就是去做日志收集的。肯定是具备条件的。

### 3、后台异步、主动Flush

+ Kafka有好多好多异步的这种IO级别的Strategy。
+ 它能做什么呢？它能将连续的小块组成一个大块的物理的文件。
+ 从而提高整体的性能。
+ Strategy可能会尝试的去将一些操作重新按照顺序去排好，从而减少磁盘移动的时间。
+ 然后充分的去利用空闲得的内存。
+ 这跟内存是非JVM级别的内存了。
+ Kafka的读写基本上都是在PageCache上进行的。
+ 如果生产者跟消费者速度差不多，相当，甚至都不需要通过物理级别的这种磁盘去做数据交换。
+ 直接就读PageCache了。
+ 即使是重启自己的Kafka。那其实PageCache永远是可用的。
+ 操作系统级别的PageCache，即使你服务器重启它还是存在的。
+ 但是OS级别的就会不行了。
+ JVM的内存你说你Tomcat重启了，那就回很多丢了，你要进去加载。

### 4、预读策略，IO调度

+ 这些就是Kafka高性能的原因

## 10、PageCache是什么？

![image-20220702190300003](assets/image-20220702190300003.png)



















































